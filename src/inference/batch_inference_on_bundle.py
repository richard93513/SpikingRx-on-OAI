#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å–®ä¸€æª”æ¡ˆå®Œæˆï¼š
1. fullgrid â†’ SpikingRx inference (T=3, base_ch=16)
2. è¼¸å‡º infer_llr_int8.bin
3. å‘¼å« OAI ldpctest_spx è§£ç¢¼ â†’ decoded_bits.bin
4. æ‹¿ txbits.bin æ¯”å° â†’ è¨ˆç®— BER
"""

import os
import sys
import json
import glob
import numpy as np
import torch
import subprocess
from pathlib import Path
import argparse

# ----------------------------------------------------
# Import æ¨¡å‹èˆ‡ tensor loader
# ----------------------------------------------------
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SRC_DIR     = os.path.join(CURRENT_DIR, "..")
DATA_DIR    = os.path.join(SRC_DIR, "data")

if SRC_DIR not in sys.path:
    sys.path.append(SRC_DIR)
if DATA_DIR not in sys.path:
    sys.path.append(DATA_DIR)

from models.spikingrx_model import SpikingRxModel
from data.oai_to_spikingrx_tensor import load_oai_fullgrid


# ----------------------------------------------------
# LLR â†’ int8 çµ¦ OAI decoder
# ----------------------------------------------------
def save_llr_for_oai_decoder(llr_tensor, out_path, llr_clip, flip_sign, G):
    llr = llr_tensor.detach().cpu().numpy().astype(np.float32).reshape(-1)

    if len(llr) != G:
        raise ValueError(f"LLR size {len(llr)} != G={G}")

    if flip_sign:
        llr = -llr

    llr_norm = np.clip(llr / llr_clip, -1.0, 1.0)
    llr_int8 = np.round(llr_norm * 127).astype(np.int8)
    llr_int8.tofile(out_path)
    return llr_int8


# ----------------------------------------------------
# è¼‰å…¥ txbits (packed â†’ bits)
# ----------------------------------------------------
def load_txbits_unpacked(bundle_dir, A):
    tx_path = os.path.join(bundle_dir, "txbits.bin")
    tx_bytes = np.fromfile(tx_path, dtype=np.uint8)
    bits = np.unpackbits(tx_bytes)[:A].astype(np.uint8)
    return bits


# ----------------------------------------------------
# è§£æ ldpc_cfg.txtï¼ˆOAI ç”¢ç”Ÿçš„ txt ç‰ˆæœ¬ï¼‰
# ----------------------------------------------------
def parse_ldpc_cfg_txt(path):
    cfg = {}
    with open(path, "r") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) != 2:
                continue
            key, val = parts
            try:
                cfg[key] = int(val)
            except ValueError:
                pass
    return cfg


# ----------------------------------------------------
# è¨ˆç®— BER
# ----------------------------------------------------
def calc_ber(tx, dec):
    N = min(len(tx), len(dec))
    if N == 0:
        return 1.0
    return np.sum(tx[:N] != dec[:N]) / N


# ----------------------------------------------------
# ä¸»æµç¨‹
# ----------------------------------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--bundle_root",
        type=str,
        default="/home/richard93513/SpikingRx-on-OAI/spx_records/bundle"
    )
    parser.add_argument(
        "--ckpt",
        type=str,
        default="/home/richard93513/SpikingRx-on-OAI/src/train/best_spikingrx_model.pth"
    )
    parser.add_argument(
        "--decoder",
        type=str,
        default="/home/richard93513/openairinterface5g/cmake_targets/ran_build/build/ldpctest_spx"
    )
    args = parser.parse_args()

    device_conv = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device_fc   = torch.device("cpu")

    print(f"[Device] conv={device_conv},  readout={device_fc}")

    # ----------------------------------------------------
    # å»ºç«‹æ¨¡å‹ï¼ˆT=3, base_ch=16ï¼‰
    # ----------------------------------------------------
    model = SpikingRxModel(
        in_ch=2,
        base_ch=16,          # ğŸ‘ˆ è·Ÿè¨“ç·´æ™‚ä¸€è‡´
        bits_per_symbol=2,
        beta=0.9,
        theta=0.5,
        llr_temperature=1.0,
        out_bits=14400,
        T=3,
        device_conv=device_conv,
        device_fc=device_fc,
    )

    # ----------------------------------------------------
    # è¼‰å…¥æ¬Šé‡
    # ----------------------------------------------------
    if not os.path.exists(args.ckpt):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° checkpoint: {args.ckpt}")

    print(f"[INFO] Loading checkpoint: {args.ckpt}")
    ckpt = torch.load(args.ckpt, map_location="cpu")
    model.load_state_dict(ckpt)
    model.eval()

    # ----------------------------------------------------
    # æƒæ bundles
    # ----------------------------------------------------
    bundle_dirs = sorted(glob.glob(f"{args.bundle_root}/f*_s*"))
    print(f"[INFO] Found {len(bundle_dirs)} bundles")

    all_results = []

    for bdir in bundle_dirs:
        print("\n====================================================")
        print(f"[Bundle] {bdir}")

        # -----------------------
        # è®€å– config
        # -----------------------
        cfg_txt = os.path.join(bdir, "ldpc_cfg.txt")
        if not os.path.exists(cfg_txt):
            print("[SKIP] æ²’æœ‰ ldpc_cfg.txt")
            continue

        cfg = parse_ldpc_cfg_txt(cfg_txt)
        if "A" not in cfg or "G" not in cfg:
            print("[SKIP] cfg è£¡æ²’æœ‰ A æˆ– G")
            continue

        A = cfg["A"]
        G = cfg["G"]

        print(f"  A={A}, G={G}")

        if G != 14400:
            print("  [SKIP] G != 14400")
            continue

        # -----------------------
        # è®€ fullgrid (T=3)
        # -----------------------
        fullgrid_path = os.path.join(bdir, "fullgrid.bin")
        if not os.path.exists(fullgrid_path):
            print("[SKIP] æ²’ fullgrid.bin")
            continue

        x, fg_meta = load_oai_fullgrid(
            fullgrid_path,
            H_out=32,
            W_out=32,
            T=3,
            device=device_conv,
        )

        # -----------------------
        # Inference
        # -----------------------
        with torch.no_grad():
            llr_vec, aux = model(x)
        # ===== åŸæœ¬çš„ DEBUGï¼ˆä¿ç•™ï¼‰=====
        print("[DEBUG] spike_rate_per_stage =")
        print(aux["spike_rate_per_stage"])
        print("[DEBUG] final_rate_mean =", aux["final_rate_mean"])
        print("[DEBUG] final_rate_std  =", aux["final_rate_std"])

        # ===== æˆæœè­‰æ“šç”¨ï¼ˆæ–°å¢ï¼Œé‡é»ï¼‰=====
        llr_np = llr_vec.cpu().numpy()
        print("[RESULT] LLR length =", len(llr_np))
        print("[RESULT] LLR[0:16] =", llr_np[:16])
        # ==================================

        llr_float_path = os.path.join(bdir, "infer_llr_float.npy")
        np.save(llr_float_path, llr_vec.cpu().numpy())
        print("  â†’ Saved float LLR for debug:", llr_float_path)

        # -----------------------
        # Save LLR (int8)
        # -----------------------
        llr_path = os.path.join(bdir, "infer_llr_int8.bin")
        save_llr_for_oai_decoder(llr_vec, llr_path, llr_clip=8.0, flip_sign=True, G=G)
        print(f"  â†’ Saved LLR: {llr_path}")
	
        # -----------------------
        # å‘¼å« OAI ldpctest_spx
        # -----------------------
        dec_path = os.path.join(bdir, "decoded_bits.bin")
        cmd = [
            args.decoder,
            llr_path,
            cfg_txt,
            dec_path,
        ]
        print("  exec:", " ".join(cmd))
        subprocess.run(cmd)

        if not os.path.exists(dec_path):
            print("  [FAIL] decoder æ²’è¼¸å‡º decoded_bits.bin")
            continue

        # -----------------------
        # è¨ˆç®— BER
        # -----------------------
        tx_bits = load_txbits_unpacked(bdir, A)
        dec_bits = np.fromfile(dec_path, dtype=np.uint8)[:A]

        ber = calc_ber(tx_bits, dec_bits)
        print(f"  [BER] {ber:.6f}")

        all_results.append((os.path.basename(bdir), ber))

    # ----------------------------------------------------
    # æœ€å¾Œç¸½çµ
    # ----------------------------------------------------
    print("\n==================== ALL RESULTS ====================")
    for name, ber in all_results:
        print(f"{name:15s} â†’ BER = {ber:.6f}")


if __name__ == "__main__":
    main()
    

